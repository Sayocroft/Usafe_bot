{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import warnings\n",
    "from dotenv import load_dotenv\n",
    "import pdfplumber\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.docstore.document import Document\n",
    "from langchain import hub\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hate crimes types\n",
    "\n",
    "HATE_CRIMES_TYPE = {\n",
    "    'anti_religious_def.pdf': 'Anti-religious Hate Crime',\n",
    "    'racist_def.pdf': 'Racist and Xenophobic Hate Crime',\n",
    "    'gender_lgbt_def.pdf': 'Gender and LGBTQ+ Hate Crime'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load PDFs using pdfplumber\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Extracts text from a PDF using pdfplumber and returns a list of Document objects.\n",
    "    \"\"\"\n",
    "    extracted_text = \"\"\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                extracted_text += page_text + \"\\n\"\n",
    "    return [Document(page_content=extracted_text, metadata={\"source\": pdf_path})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PDFs for each category\n",
    "anti_religious_docs = extract_text_from_pdf('/Users/sayo/personal_projects/Usafe_bot/data/anti_religious_def.pdf')\n",
    "gender_lgbt_docs = extract_text_from_pdf('/Users/sayo/personal_projects/Usafe_bot/data/gender_lgbt_def.pdf')\n",
    "general_docs = extract_text_from_pdf('/Users/sayo/personal_projects/Usafe_bot/data/general.pdf')\n",
    "racist_docs = extract_text_from_pdf('/Users/sayo/personal_projects/Usafe_bot/data/racist_def.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Chunk Documents\n",
    "def chunk_documents(documents, chunk_size=800, chunk_overlap=80):\n",
    "    \"\"\"\n",
    "    Splits documents into smaller chunks for embedding.\n",
    "    \"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    return text_splitter.split_documents(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks in anti-religious document: 202\n",
      "Number of chunks in gender/LGBT document: 52\n",
      "Number of chunks in general document: 18\n",
      "Number of chunks in racist document: 45\n",
      "Total number of chunks: 317\n"
     ]
    }
   ],
   "source": [
    "# Chunk each document category\n",
    "anti_religious_chunks = chunk_documents(anti_religious_docs)\n",
    "gender_lgbt_chunks = chunk_documents(gender_lgbt_docs)\n",
    "general_chunks = chunk_documents(general_docs)\n",
    "racist_chunks = chunk_documents(racist_docs)\n",
    "\n",
    "# Print the number of chunks for each document\n",
    "print(f\"Number of chunks in anti-religious document: {len(anti_religious_chunks)}\")\n",
    "print(f\"Number of chunks in gender/LGBT document: {len(gender_lgbt_chunks)}\")\n",
    "print(f\"Number of chunks in general document: {len(general_chunks)}\")\n",
    "print(f\"Number of chunks in racist document: {len(racist_chunks)}\")\n",
    "\n",
    "# Calculate total number of chunks across all documents\n",
    "total_chunks = len(general_chunks) + len(racist_chunks) + len(gender_lgbt_chunks) + len(anti_religious_chunks)\n",
    "print(f\"Total number of chunks: {total_chunks}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_chunks = anti_religious_chunks + gender_lgbt_chunks + general_chunks + racist_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create Embedding Vector Store\n",
    "def create_vector_store(chunks, db_name='usafe_combined'):\n",
    "    \"\"\"\n",
    "    Creates a vector store using HuggingFace embeddings and saves it locally.\n",
    "    \"\"\"\n",
    "    embedding_model = HuggingFaceEmbeddings(model_name='sentence-transformers/all-mpnet-base-v2')\n",
    "    vector_store = FAISS.from_documents(chunks, embedding=embedding_model)\n",
    "    vector_store.save_local(f\"./vector_databases/{db_name}\")\n",
    "    print(f\"Vector store '{db_name}' created and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store 'usafe_combined' created and saved.\n"
     ]
    }
   ],
   "source": [
    "# Create vector store for combined data\n",
    "create_vector_store(all_chunks, db_name='usafe_combined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Load Vector Store and Create Retriever\n",
    "def load_vector_store(db_path='./vector_databases/vector_db_usafe_combined'):\n",
    "    \"\"\"\n",
    "    Loads a vector store from a local directory and returns a retriever.\n",
    "    \"\"\"\n",
    "    embedding_model = HuggingFaceEmbeddings(model_name='sentence-transformers/all-mpnet-base-v2')\n",
    "    vector_store = FAISS.load_local(folder_path=db_path, embeddings=embedding_model, allow_dangerous_deserialization=True)\n",
    "    return vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize retriever for combined data\n",
    "combined_retriever = load_vector_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.vectorstores.base.VectorStoreRetriever"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(combined_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('/Users/sayo/personal_projects/Usafe_bot/data/usafe_prompt.txt', 'r') as file:\n",
    "    #user_prompt = file.read()\n",
    "\n",
    "#print(user_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[`create_stuff_documents_chain`](https://api.python.langchain.com/en/latest/chains/langchain.chains.combine_documents.stuff.create_stuff_documents_chain.html#langchain.chains.combine_documents.stuff.create_stuff_documents_chain)\n",
    "\n",
    "- takes a list of documents and formats them all into a prompt, then passes that prompt to an LLM\n",
    "- passes ALL documents, so you should make sure it fits within the context window of the LLM being used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[`create_retrieval_chain`](https://api.python.langchain.com/en/latest/chains/langchain.chains.retrieval.create_retrieval_chain.html#langchain.chains.retrieval.create_retrieval_chain)\n",
    "\n",
    "- takes in a user inquiry, which is then passed to the retriever to fetch relevant documents\n",
    "- those documents (and original inputs) are then passed to an LLM to generate a response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_chains(retriever):\n",
    "    \"\"\"\n",
    "    this function connects stuff_documents_chain with retrieval_chain\n",
    "    \"\"\"\n",
    "    stuff_documents_chain = create_stuff_documents_chain(\n",
    "        llm=llm,\n",
    "        prompt=hub.pull(\"langchain-ai/retrieval-qa-chat\")\n",
    "    )\n",
    "    retrieval_chain = create_retrieval_chain(\n",
    "        retriever=retriever,\n",
    "        combine_docs_chain=stuff_documents_chain\n",
    "    )\n",
    "    return retrieval_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Initialize LLM\n",
    "def initialize_llm(model_name=\"llama3-8b-8192\"):\n",
    "    \"\"\"\n",
    "    Initializes the LLM model with specified configurations.\n",
    "    \"\"\"\n",
    "    return ChatGroq(model=model_name, temperature=0.02, max_tokens=None, timeout=None, max_retries=2)\n",
    "\n",
    "llm = initialize_llm()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Setup Retrieval Chain\n",
    "def setup_retrieval_chain(retriever):\n",
    "    \"\"\"\n",
    "    Sets up the document chain and retrieval chain.\n",
    "    \"\"\"\n",
    "    stuff_chain = create_stuff_documents_chain(llm=llm, prompt=hub.pull(\"langchain-ai/retrieval-qa-chat\"))\n",
    "    return create_retrieval_chain(retriever=retriever, combine_docs_chain=stuff_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "usafe_retrieval_chain = setup_retrieval_chain(combined_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Detect Hate Crime Type\n",
    "def detect_hate_crime_type(inquiry, retrieval_chain=usafe_retrieval_chain):\n",
    "    \"\"\"\n",
    "    Detects the type of hate crime based on user input\n",
    "    \"\"\"\n",
    "    result = retrieval_chain.invoke({\"input\": inquiry})\n",
    "    detected_type = HATE_CRIMES_TYPE.get(result['context'][0].dict()['metadata']['source'].split('/')[-1], \"Unknown\")\n",
    "    return detected_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Racist and Xenophobic Hate Crime\n"
     ]
    }
   ],
   "source": [
    "print(detect_hate_crime_type(\"I was attacked because of my ethnicity.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Interactive Query Function\n",
    "def handle_user_query(inquiry):\n",
    "    \"\"\"\n",
    "    Handles user query by detecting hate crime type and offering options.\n",
    "    \"\"\"\n",
    "    detected_type = detect_hate_crime_type(inquiry)\n",
    "    print(f\"\\nDetected Hate Crime Type: {detected_type}\")\n",
    "\n",
    "    # Present user options\n",
    "    print(\"\\nWhat information would you like to access?\")\n",
    "    print(\"1. Relevant Laws Germany\")\n",
    "    print(\"2. Local Resources and Support\")\n",
    "    print(\"3. Steps to Report a Crime in Germany\")\n",
    "    print(\"4. Generic Information\")\n",
    "    \n",
    "    option = input(\"Enter your choice (1-4): \")\n",
    "\n",
    "    # using the option selected by the user to query the pdf\n",
    "    pdf_query = \"\"\n",
    "    if option == '1':\n",
    "        pdf_query = \"Relevant laws related to hate crimes in Germany\"\n",
    "    elif option == '2':\n",
    "        pdf_query = \"Local resources: NGOs, Legal Aid, Counseling, etc to support hate crime victims\"\n",
    "    elif option == '3':\n",
    "        pdf_query = \"Steps on how to report a hate crime in Germany\"\n",
    "    elif option == '4':\n",
    "        pdf_query = \"General information on hate crimes, psychological effects, and resources\"\n",
    "    else:\n",
    "        print(\"Invalid option. Please try again.\")\n",
    "        return\n",
    "    \n",
    "     # Add metadata to specify the PDF file you want to query\n",
    "    metadata_filter = {\"pdf_name\": \"general.pdf\"}\n",
    "\n",
    "    # Retrieve and print response from the vector store\n",
    "    response = usafe_retrieval_chain.invoke({\"input\": pdf_query})\n",
    "    print(\"\\nResponse:\\n\", response['answer'].strip(\"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected Hate Crime Type: Anti-religious Hate Crime\n",
      "\n",
      "What information would you like to access?\n",
      "1. Relevant Laws Germany\n",
      "2. Local Resources and Support\n",
      "3. Steps to Report a Crime in Germany\n",
      "4. Generic Information\n",
      "\n",
      "Response:\n",
      " Based on the provided context, here are some local resources that can support hate crime victims in Germany:\n",
      "\n",
      "1. NGOs:\n",
      "\t* ReachOut Berlin: Offers assistance for individuals facing hate crime incidents. Contact: info@reachoutberlin.de, Address: Oranienburger Str. 27, 10117 Berlin\n",
      "2. Legal Aid:\n",
      "\t* Antidiskriminierungsstelle des Bundes (Federal Anti-Discrimination Agency): Offers counseling and support for those facing discrimination, including hate crimes. Contact: [insert contact information]\n",
      "3. Counseling:\n",
      "\t* Antidiskriminierungsstelle des Bundes (Federal Anti-Discrimination Agency): Provides information on rights and connects individuals with local support. Contact: [insert contact information]\n",
      "4. Online Reporting Platforms:\n",
      "\t* Online Strafanzeige (Online Criminal Complaint): Allows individuals to file criminal complaints online, including hate crimes. Contact: Depends on the federal state; typically managed by local police authorities. Link: online-strafanzeige.de\n",
      "\t* Meldestelle Respect!: A platform to report hate speech and receive expert analysis. Contact: Email: info@meldestelle-respect.de, Link: meldestelle-respect.de/faq/\n",
      "\n",
      "These resources can provide support, counseling, and legal aid to hate crime victims in Germany.\n"
     ]
    }
   ],
   "source": [
    "handle_user_query(\"I was attacked because by nazi group\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Interactive Query Function (No Response Retrieval)\n",
    "def handle_user_query(inquiry):\n",
    "    \"\"\"\n",
    "    Handles user query by detecting hate crime type and offering options.\n",
    "    \"\"\"\n",
    "    detected_type = detect_hate_crime_type(inquiry)\n",
    "    print(f\"\\nDetected Hate Crime Type: {detected_type}\")\n",
    "\n",
    "    # Present user options\n",
    "    print(\"\\nWhat information would you like to access?\")\n",
    "    print(\"1. Relevant Laws Germany\")\n",
    "    print(\"2. Local Resources and Support\")\n",
    "    print(\"3. Steps to Report a Crime in Germany\")\n",
    "    print(\"4. Generic Information\")\n",
    "    \n",
    "    option = input(\"Enter your choice (1-4): \")\n",
    "\n",
    "    # Confirm the selected option without invoking a response\n",
    "    if option == '1':\n",
    "        print(\"\\nYou selected: Relevant Laws Germany.\")\n",
    "    elif option == '2':\n",
    "        print(\"\\nYou selected: Local Resources and Support.\")\n",
    "    elif option == '3':\n",
    "        print(\"\\nYou selected: Steps to Report a Crime in Germany.\")\n",
    "    elif option == '4':\n",
    "        print(\"\\nYou selected: Generic Information.\")\n",
    "    else:\n",
    "        print(\"Invalid option. Please try again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected Hate Crime Type: Gender and LGBTQ+ Hate Crime\n",
      "\n",
      "What information would you like to access?\n",
      "1. Relevant Laws Germany\n",
      "2. Local Resources and Support\n",
      "3. Steps to Report a Crime in Germany\n",
      "4. Generic Information\n",
      "\n",
      "You selected: Local Resources and Support.\n"
     ]
    }
   ],
   "source": [
    "handle_user_query(\"I was attacked because of my sexual orientation. What can I do?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_hate_type(\n",
    "    inquiry,\n",
    "    retrieval_chain=react_retrieval_chain\n",
    "):\n",
    "    result = retrieval_chain.invoke({\"input\": inquiry})\n",
    "    hate_type = HATE_CRIMES_TYPE[result['context'][0].dict()['metadata']['source'].split('/')[-1]]\n",
    "    return hate_type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anti-religious hate crime\n"
     ]
    }
   ],
   "source": [
    "print(detect_hate_type(\"I was attacked because of my religion\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hate_type=detect_hate_type(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_laws = False\n",
    "resources_available = False\n",
    "steps_how_to_report_crime = False \n",
    "general_info = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    query = f\"\"\"\n",
    "    I have been facing a hate crime of type {hate_type}.\n",
    "    {'Please give me some legal advice.' * relevant_laws}\n",
    "    {'Please tell me what are the local resources available.' * resources_available}\n",
    "    {'Please explain the steps on how to report a hate crime.' * steps_how_to_report_crime}\n",
    "    {'Please provide me with some general information.' * general_info}\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nI have been facing a hate crime of type anti-religious hate crime.\\n\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents Retrieved: [Document(metadata={'source': '/Users/sayo/personal_projects/Usafe_bot/data/anti_religious_def.pdf', 'page': 1}, page_content='-\\nA\\nBlack\\nMuslim\\nwoman\\nwas\\nsubjected\\nto\\nracist\\nand\\nanti-Muslim\\nthreats\\nand\\ninsults\\non\\na\\ntrain.\\n-\\nA\\nmale\\nMuslim\\nactivist\\nreceived\\ndeath\\nthreats\\nvia\\nemail.\\nThis\\nwas\\none\\nin\\na\\nseries\\nof\\nsimilar\\nincidents.\\n-\\nA\\nmale\\nMuslim\\nactivist\\nreceived\\na\\nletter\\ncontaining\\nanti-Muslim\\nand\\nxenophobic\\ninsults\\nand\\nthreats,\\nas\\nwell\\nas\\nNazi\\nsymbols.\\nThis\\nwas\\none\\nin\\na\\nseries\\nof\\nsimilar\\nincidents.\\n-\\nA\\nmale\\nMuslim\\nactivist\\nwas\\nrepeatedly\\nthreatened\\non\\nTwitter.\\nThis\\nwas\\none\\nin\\na\\nseries\\nof\\nsimilar\\nincidents.\\n-\\nA\\nMuslim\\nwoman\\nwas\\nsubjected\\nto\\nanti-Muslim\\ninsults,\\nthreatened\\nwith\\na\\nknife\\nand\\nphysically\\nassaulted\\nby\\na\\nperpetrator\\nwho\\nattempted\\nto\\nremove\\nher\\nheadscarf.\\n-\\nA\\nMuslim-owned\\nshop\\nwas\\nvandalized\\nand\\na\\nwindow\\nwas\\nshattered\\nwhen\\nreligious\\nmusic\\nwas\\nplayed\\ninside\\nthe\\nshop\\nduring\\nRamadan.\\n-\\nA\\nMuslim\\nwoman\\nwearing\\na'), Document(metadata={'source': '/Users/sayo/personal_projects/Usafe_bot/data/anti_religious_def.pdf', 'page': 13}, page_content=\"threats\\nvia\\nsocial\\nmedia.\\n-\\nThe\\nwindow\\nof\\na\\nMuslim\\ndoctor's\\noffice\\nwas\\nbroken\\nand\\nvandalized\\nwith\\na\\nswastika\\ninscription.\\n-\\nA\\nSyrian\\nperson\\nwas\\nstabbed\\nand\\nsubjected\\nto\\nracist\\ninsults.\\n-\\nA\\nSyrian\\nchild\\nwas\\nshot\\nat\\nand\\ninjured\\nwith\\nan\\nair\\nrifle.\\n-\\nA\\nMuslim\\ngirl\\nwearing\\na\\nheadscarf\\nwas\\nphysically\\nassaulted\\nat\\na\\nbus\\nstop.\\n-\\nA\\nMuslim\\ngirl\\nwearing\\na\\nheadscarf\\nwas\\nphysically\\nassaulted\\nin\\na\\nparking\\nlot.\\n-\\nA\\nMuslim\\nwoman\\nwearing\\na\\nheadscarf\\nwas\\nsubjected\\nto\\nanti-Muslim\\ninsults\\nand\\nphysically\\nassaulted\\nat\\na\\npublic\\ntransportation\\nstop.\\n-\\nA\\nTurkish\\ncommunity\\nclub\\nwas\\ntargeted\\nin\\nan\\narson\\nattack.\\n-\\nA\\ntree\\nnear\\na\\nMuslim\\nfestival\\nhad\\npig\\nparts\\nnailed\\nto\\nit.\\n-\\nA\\nMuslim\\nwoman\\nwearing\\na\\nheadscarf\\nwas\\nsubjected\\nto\\nanti-Muslim\\ninsults\\nand\\nphysically\\nassaulted.\\n-\\nTwo\\nTurkish\\nMuslim\\nwomen\\nwere\\nsubjected\\nto\"), Document(metadata={'source': '/Users/sayo/personal_projects/Usafe_bot/data/anti_religious_def.pdf', 'page': 0}, page_content='assaulted\\nwith\\na\\nmetal\\nobject\\nbecause\\nthey\\nspoke\\nTurkish\\nin\\npublic.\\n-\\nA\\nMuslim\\nwoman\\nwas\\nphysically\\nassaulted\\nduring\\nan\\nattempt\\nto\\nremove\\nher\\nheadscarf.\\n-\\nA\\nMuslim\\nfamily\\nwas\\nspat\\nat\\nand\\nsubjected\\nto\\nxenophobic\\ninsults.\\n-\\nA\\nMuslim\\nwoman\\nwas\\nsubjected\\nto\\nthreatening\\nbehaviour,\\nincluding\\na\\nNazi\\nsalute,\\nwhile\\nwalking\\nalone\\nin\\nthe\\nstreet.'), Document(metadata={'source': '/Users/sayo/personal_projects/Usafe_bot/data/anti_religious_def.pdf', 'page': 22}, page_content='Muslim\\ngirls\\nwere\\nthreatened\\nwith\\na\\nknife\\nand\\nsubjected\\nto\\nanti-Muslim\\ninsults\\nby\\na\\nwoman\\noutside\\na\\nmosque.\\n-\\nMuslim\\nworshippers\\nwere\\nthreatened\\nwhen\\na\\nletter\\ncontaining\\nanti-Muslim\\nthreats\\nwas\\nsent\\nto\\na\\nmosque\\nby\\na\\nhate\\ngroup.\\nThe\\ncommunity\\nhad\\npreviously\\nbeen\\ntargeted\\nin\\nsimilar\\nincidents.\\n-\\nThe\\nMuslim\\ncommunity\\nwas\\nthreatened\\nwhen\\na\\nletter\\ncontaining\\nanti-Muslim\\nthreats\\nand\\na\\nswastika\\nwas\\nsent\\nto\\na\\nmosque\\nby\\na\\nhate\\ngroup.\\nThe\\ncommunity\\nhad\\npreviously\\nbeen\\ntargeted\\nin\\nhate\\nincidents.\\n-\\nThe\\nMuslim\\ncommunity\\nwas\\nthreatened\\nwhen\\na\\nletter\\ncontaining\\nanti-Muslim\\nthreats\\nwas\\nsent\\nto\\na\\nmosque\\nby\\na\\nhate\\ngroup.\\nThe\\nletter\\nalso\\nreferenced\\na\\nrecent\\narson\\nattack\\ntargeting\\nthe\\nmosque.\\n-\\nThe\\nMuslim\\ncommunity\\nwas\\nthreatened\\nwhen\\na\\nletter\\ncontaining\\nanti-Muslim\\nthreats\\nand\\na\\nswastika\\nwas\\nsent\\nto\\na')]\n"
     ]
    }
   ],
   "source": [
    "test_query = \"What should I do if I am being harassed for being Muslim?\"\n",
    "docs = combined_retriever.get_relevant_documents(test_query)\n",
    "print(\"Documents Retrieved:\", docs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
