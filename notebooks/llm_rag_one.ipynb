{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HATE_CRIMES_TYPE = {\n",
    "\t'anti_religious_def.pdf': 'anti-religious hate crime',\n",
    "\t'racist_def.pdf': 'racist and xenophobic hate crime',\n",
    "\t'gender_lgbt_def.pdf': 'gender and lgbt hate crime'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "def load_pdf_data(pdf_path):\n",
    "    \"\"\"\n",
    "    this function loads text data from pdf file\n",
    "    \"\"\"\n",
    "    loader = PyPDFLoader(file_path=pdf_path)\n",
    "    documents = loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "anti_religious = load_pdf_data(pdf_path='/Users/sayo/personal_projects/Usafe_bot/data/anti_religious_def.pdf')\n",
    "gender_lgbt = load_pdf_data(pdf_path='/Users/sayo/personal_projects/Usafe_bot/data/gender_lgbt_def.pdf')\n",
    "general = load_pdf_data(pdf_path='/Users/sayo/personal_projects/Usafe_bot/data/general.pdf')\n",
    "racist = load_pdf_data(pdf_path='/Users/sayo/personal_projects/Usafe_bot/data/racist_def.pdf')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "def split_documents(documents, chunk_size=800, chunk_overlap=80):\n",
    "    \"\"\"\n",
    "    this function splits documents into chunks of given size and overlap\n",
    "    \"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap\n",
    "    )\n",
    "    chunks = text_splitter.split_documents(documents=documents)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks in anti-religious document: 226\n",
      "Number of chunks in gender/LGBT document: 58\n",
      "Number of chunks in general document: 23\n",
      "Number of chunks in racist document: 48\n",
      "Total number of chunks: 355\n"
     ]
    }
   ],
   "source": [
    "# Split each loaded document into chunks\n",
    "anti_religious_chunks = split_documents(anti_religious)\n",
    "gender_lgbt_chunks = split_documents(gender_lgbt)\n",
    "general_chunks = split_documents(general)\n",
    "racist_chunks = split_documents(racist)\n",
    "\n",
    "# Print the number of chunks for each document\n",
    "print(f\"Number of chunks in anti-religious document: {len(anti_religious_chunks)}\")\n",
    "print(f\"Number of chunks in gender/LGBT document: {len(gender_lgbt_chunks)}\")\n",
    "print(f\"Number of chunks in general document: {len(general_chunks)}\")\n",
    "print(f\"Number of chunks in racist document: {len(racist_chunks)}\")\n",
    "\n",
    "# Calculate total number of chunks across all documents\n",
    "total_chunks = len(general_chunks) + len(racist_chunks) + len(gender_lgbt_chunks) + len(anti_religious_chunks)\n",
    "print(f\"Total number of chunks: {total_chunks}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_chunks = anti_religious_chunks + gender_lgbt_chunks + general_chunks + racist_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "def create_embedding_vector_db(chunks, db_name):\n",
    "    \"\"\"\n",
    "    this function uses the open-source embedding model HuggingFaceEmbeddings \n",
    "    to create embeddings and store those in a vector database called FAISS, \n",
    "    which allows for efficient similarity search\n",
    "    \"\"\"\n",
    "    # instantiate embedding model\n",
    "    embedding = HuggingFaceEmbeddings(\n",
    "        model_name='sentence-transformers/all-mpnet-base-v2'\n",
    "    )\n",
    "    # create the vector store \n",
    "    vectorstore = FAISS.from_documents(\n",
    "        documents=chunks,\n",
    "        embedding=embedding\n",
    "    )\n",
    "    # save vector database locally\n",
    "    vectorstore.save_local(f\"./vector_databases/vector_db_{db_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sayo/personal_projects/Usafe_bot/.venv/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "create_embedding_vector_db(chunks=all_chunks, db_name='usafe_combined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_from_vector_db(vector_db_path):\n",
    "    \"\"\"\n",
    "    this function spits out a retriever object from a local vector database\n",
    "    \"\"\"\n",
    "    # instantiate embedding model\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name='sentence-transformers/all-mpnet-base-v2'\n",
    "    )\n",
    "    react_vectorstore = FAISS.load_local(\n",
    "        folder_path=vector_db_path,\n",
    "        embeddings=embeddings,\n",
    "        allow_dangerous_deserialization=True\n",
    "    )\n",
    "    retriever = react_vectorstore.as_retriever()\n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_retriever = retrieve_from_vector_db(vector_db_path='./vector_databases/vector_db_usafe_combined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.vectorstores.base.VectorStoreRetriever"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(combined_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('/Users/sayo/personal_projects/Usafe_bot/data/usafe_prompt.txt', 'r') as file:\n",
    "    #user_prompt = file.read()\n",
    "\n",
    "#print(user_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[`create_stuff_documents_chain`](https://api.python.langchain.com/en/latest/chains/langchain.chains.combine_documents.stuff.create_stuff_documents_chain.html#langchain.chains.combine_documents.stuff.create_stuff_documents_chain)\n",
    "\n",
    "- takes a list of documents and formats them all into a prompt, then passes that prompt to an LLM\n",
    "- passes ALL documents, so you should make sure it fits within the context window of the LLM being used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[`create_retrieval_chain`](https://api.python.langchain.com/en/latest/chains/langchain.chains.retrieval.create_retrieval_chain.html#langchain.chains.retrieval.create_retrieval_chain)\n",
    "\n",
    "- takes in a user inquiry, which is then passed to the retriever to fetch relevant documents\n",
    "- those documents (and original inputs) are then passed to an LLM to generate a response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains.retrieval import create_retrieval_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_chains(retriever):\n",
    "    \"\"\"\n",
    "    this function connects stuff_documents_chain with retrieval_chain\n",
    "    \"\"\"\n",
    "    stuff_documents_chain = create_stuff_documents_chain(\n",
    "        llm=llm,\n",
    "        prompt=hub.pull(\"langchain-ai/retrieval-qa-chat\")\n",
    "    )\n",
    "    retrieval_chain = create_retrieval_chain(\n",
    "        retriever=retriever,\n",
    "        combine_docs_chain=stuff_documents_chain\n",
    "    )\n",
    "    return retrieval_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"llama3-8b-8192\",\n",
    "    temperature=0.02,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "react_retrieval_chain = connect_chains(combined_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_output(\n",
    "    inquiry,\n",
    "    retrieval_chain=react_retrieval_chain\n",
    "):\n",
    "    result = retrieval_chain.invoke({\"input\": inquiry})\n",
    "    print(result['answer'].strip(\"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the provided context, a hate crime (also known as a bias crime) is a crime where a perpetrator targets a victim due to their physical appearance or perceived membership in a specific social group. These groups may include race, ethnicity, disability, language, nationality, political views, age, religion, sex, gender identity, or sexual orientation.\n"
     ]
    }
   ],
   "source": [
    "print_output(\"What is a hate crime?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm so sorry to hear that you're experiencing harassment because of your religion. It's unacceptable and illegal. Here are some steps you can take:\n",
      "\n",
      "1. Report the incident to the authorities: File a police report and provide as much detail as possible about the incident, including the date, time, location, and any witnesses.\n",
      "2. Seek support from a trusted friend or family member: Talking to someone you trust can help you process your emotions and feel supported.\n",
      "3. Reach out to a Muslim organization or community center: Many Muslim organizations and community centers have resources and support services for victims of harassment and discrimination.\n",
      "4. Consider seeking counseling: Harassment and discrimination can be emotionally draining, and counseling can help you cope with the emotional impact.\n",
      "5. Document the incident: Keep a record of the incident, including any evidence you have, such as photos, videos, or witness statements.\n",
      "6. Consider reporting the incident to a hate crime hotline: Many organizations, such as the Anti-Defamation League and the Southern Poverty Law Center, have hotlines and resources for reporting hate crimes.\n",
      "7. Take care of yourself: Remember that you don't have to face this alone. Reach out to friends, family, or a therapist for support.\n",
      "\n",
      "Remember, you are not alone, and there are people who care about you and want to help.\n"
     ]
    }
   ],
   "source": [
    "print_output(\"i was harassed because i'm a muslim, what shall i do?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_hate_type(\n",
    "    inquiry,\n",
    "    retrieval_chain=react_retrieval_chain\n",
    "):\n",
    "    result = retrieval_chain.invoke({\"input\": inquiry})\n",
    "    hate_type = HATE_CRIMES_TYPE[result['context'][0].dict()['metadata']['source'].split('/')[-1]]\n",
    "    return hate_type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anti-religious hate crime\n"
     ]
    }
   ],
   "source": [
    "print(detect_hate_type(\"I was attacked because of my religion\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "hate_type=detect_hate_type(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_laws = False\n",
    "resources_available = False\n",
    "steps_how_to_report_crime = False \n",
    "general_info = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "    query = f\"\"\"\n",
    "    I have been facing a hate crime of type {hate_type}.\n",
    "    {'Please give me some legal advice.' * relevant_laws}\n",
    "    {'Please tell me what are the local resources available.' * resources_available}\n",
    "    {'Please explain the steps on how to report a hate crime.' * steps_how_to_report_crime}\n",
    "    {'Please provide me with some general information.' * general_info}\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nI have been facing a hate crime of type anti-religious hate crime.\\n\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'sayo'*False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hate\n",
      "Crime\n",
      "Definition\n",
      "●\n",
      "A\n",
      "hate\n",
      "crime\n",
      "(also\n",
      "known\n",
      "as\n",
      "a\n",
      "bias\n",
      "crime)\n",
      "is\n",
      "a\n",
      "crime\n",
      "where\n",
      "a\n",
      "perpetrator\n",
      "targets\n",
      "a\n",
      "victim\n",
      "due\n",
      "to\n",
      "their\n",
      "physical\n",
      "appearance\n",
      "or\n",
      "perceived\n",
      "membership\n",
      "in\n",
      "a\n",
      "specific\n",
      "social\n",
      "group.\n",
      "Such\n",
      "groups\n",
      "may\n",
      "include\n",
      "race,\n",
      "ethnicity ,\n",
      "disability ,\n",
      "language,\n",
      "nationality ,\n",
      "political\n",
      "views,\n",
      "age,\n",
      "religion,\n",
      "sex,\n",
      "gender\n",
      "identity ,\n",
      "or\n",
      "sexual\n",
      "orientation.\n",
      "Non-criminal\n",
      "actions\n",
      "motivated\n",
      "by\n",
      "these\n",
      "biases\n",
      "are\n",
      "often\n",
      "termed\n",
      "“bias\n",
      "incidents.”\n",
      "•\n",
      "Examples\n",
      "of\n",
      "hate\n",
      "crimes\n",
      "include:\n",
      "•\n",
      "Physical\n",
      "assault,\n",
      "homicide,\n",
      "damage\n",
      "to\n",
      "property\n",
      "•\n",
      "Bullying,\n",
      "harassment,\n",
      "verbal\n",
      "abuse,\n",
      "offensive\n",
      "graffiti,\n",
      "or\n",
      "hate\n",
      "mail\n",
      "History\n",
      "of\n",
      "Hate\n",
      "Crimes\n",
      "•\n",
      "Term\n",
      "Origin:\n",
      "The\n",
      "term\n",
      "“hate\n",
      "crime”\n",
      "gained\n",
      "common\n",
      "usage\n",
      "in\n",
      "the\n",
      "U.S.\n",
      "during\n",
      "the\n",
      "1980s,\n",
      "although\n",
      "similar\n",
      "crimes\n",
      "have\n",
      "historical\n",
      "roots.\n",
      "•\n",
      "Historical\n",
      "Examples:\n",
      "•\n",
      "Roman\n",
      "persecution\n",
      "of\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents Retrieved: [Document(metadata={'source': '/Users/sayo/personal_projects/Usafe_bot/data/anti_religious_def.pdf', 'page': 1}, page_content='-\\nA\\nBlack\\nMuslim\\nwoman\\nwas\\nsubjected\\nto\\nracist\\nand\\nanti-Muslim\\nthreats\\nand\\ninsults\\non\\na\\ntrain.\\n-\\nA\\nmale\\nMuslim\\nactivist\\nreceived\\ndeath\\nthreats\\nvia\\nemail.\\nThis\\nwas\\none\\nin\\na\\nseries\\nof\\nsimilar\\nincidents.\\n-\\nA\\nmale\\nMuslim\\nactivist\\nreceived\\na\\nletter\\ncontaining\\nanti-Muslim\\nand\\nxenophobic\\ninsults\\nand\\nthreats,\\nas\\nwell\\nas\\nNazi\\nsymbols.\\nThis\\nwas\\none\\nin\\na\\nseries\\nof\\nsimilar\\nincidents.\\n-\\nA\\nmale\\nMuslim\\nactivist\\nwas\\nrepeatedly\\nthreatened\\non\\nTwitter.\\nThis\\nwas\\none\\nin\\na\\nseries\\nof\\nsimilar\\nincidents.\\n-\\nA\\nMuslim\\nwoman\\nwas\\nsubjected\\nto\\nanti-Muslim\\ninsults,\\nthreatened\\nwith\\na\\nknife\\nand\\nphysically\\nassaulted\\nby\\na\\nperpetrator\\nwho\\nattempted\\nto\\nremove\\nher\\nheadscarf.\\n-\\nA\\nMuslim-owned\\nshop\\nwas\\nvandalized\\nand\\na\\nwindow\\nwas\\nshattered\\nwhen\\nreligious\\nmusic\\nwas\\nplayed\\ninside\\nthe\\nshop\\nduring\\nRamadan.\\n-\\nA\\nMuslim\\nwoman\\nwearing\\na'), Document(metadata={'source': '/Users/sayo/personal_projects/Usafe_bot/data/anti_religious_def.pdf', 'page': 13}, page_content=\"threats\\nvia\\nsocial\\nmedia.\\n-\\nThe\\nwindow\\nof\\na\\nMuslim\\ndoctor's\\noffice\\nwas\\nbroken\\nand\\nvandalized\\nwith\\na\\nswastika\\ninscription.\\n-\\nA\\nSyrian\\nperson\\nwas\\nstabbed\\nand\\nsubjected\\nto\\nracist\\ninsults.\\n-\\nA\\nSyrian\\nchild\\nwas\\nshot\\nat\\nand\\ninjured\\nwith\\nan\\nair\\nrifle.\\n-\\nA\\nMuslim\\ngirl\\nwearing\\na\\nheadscarf\\nwas\\nphysically\\nassaulted\\nat\\na\\nbus\\nstop.\\n-\\nA\\nMuslim\\ngirl\\nwearing\\na\\nheadscarf\\nwas\\nphysically\\nassaulted\\nin\\na\\nparking\\nlot.\\n-\\nA\\nMuslim\\nwoman\\nwearing\\na\\nheadscarf\\nwas\\nsubjected\\nto\\nanti-Muslim\\ninsults\\nand\\nphysically\\nassaulted\\nat\\na\\npublic\\ntransportation\\nstop.\\n-\\nA\\nTurkish\\ncommunity\\nclub\\nwas\\ntargeted\\nin\\nan\\narson\\nattack.\\n-\\nA\\ntree\\nnear\\na\\nMuslim\\nfestival\\nhad\\npig\\nparts\\nnailed\\nto\\nit.\\n-\\nA\\nMuslim\\nwoman\\nwearing\\na\\nheadscarf\\nwas\\nsubjected\\nto\\nanti-Muslim\\ninsults\\nand\\nphysically\\nassaulted.\\n-\\nTwo\\nTurkish\\nMuslim\\nwomen\\nwere\\nsubjected\\nto\"), Document(metadata={'source': '/Users/sayo/personal_projects/Usafe_bot/data/anti_religious_def.pdf', 'page': 0}, page_content='assaulted\\nwith\\na\\nmetal\\nobject\\nbecause\\nthey\\nspoke\\nTurkish\\nin\\npublic.\\n-\\nA\\nMuslim\\nwoman\\nwas\\nphysically\\nassaulted\\nduring\\nan\\nattempt\\nto\\nremove\\nher\\nheadscarf.\\n-\\nA\\nMuslim\\nfamily\\nwas\\nspat\\nat\\nand\\nsubjected\\nto\\nxenophobic\\ninsults.\\n-\\nA\\nMuslim\\nwoman\\nwas\\nsubjected\\nto\\nthreatening\\nbehaviour,\\nincluding\\na\\nNazi\\nsalute,\\nwhile\\nwalking\\nalone\\nin\\nthe\\nstreet.'), Document(metadata={'source': '/Users/sayo/personal_projects/Usafe_bot/data/anti_religious_def.pdf', 'page': 22}, page_content='Muslim\\ngirls\\nwere\\nthreatened\\nwith\\na\\nknife\\nand\\nsubjected\\nto\\nanti-Muslim\\ninsults\\nby\\na\\nwoman\\noutside\\na\\nmosque.\\n-\\nMuslim\\nworshippers\\nwere\\nthreatened\\nwhen\\na\\nletter\\ncontaining\\nanti-Muslim\\nthreats\\nwas\\nsent\\nto\\na\\nmosque\\nby\\na\\nhate\\ngroup.\\nThe\\ncommunity\\nhad\\npreviously\\nbeen\\ntargeted\\nin\\nsimilar\\nincidents.\\n-\\nThe\\nMuslim\\ncommunity\\nwas\\nthreatened\\nwhen\\na\\nletter\\ncontaining\\nanti-Muslim\\nthreats\\nand\\na\\nswastika\\nwas\\nsent\\nto\\na\\nmosque\\nby\\na\\nhate\\ngroup.\\nThe\\ncommunity\\nhad\\npreviously\\nbeen\\ntargeted\\nin\\nhate\\nincidents.\\n-\\nThe\\nMuslim\\ncommunity\\nwas\\nthreatened\\nwhen\\na\\nletter\\ncontaining\\nanti-Muslim\\nthreats\\nwas\\nsent\\nto\\na\\nmosque\\nby\\na\\nhate\\ngroup.\\nThe\\nletter\\nalso\\nreferenced\\na\\nrecent\\narson\\nattack\\ntargeting\\nthe\\nmosque.\\n-\\nThe\\nMuslim\\ncommunity\\nwas\\nthreatened\\nwhen\\na\\nletter\\ncontaining\\nanti-Muslim\\nthreats\\nand\\na\\nswastika\\nwas\\nsent\\nto\\na')]\n"
     ]
    }
   ],
   "source": [
    "test_query = \"What should I do if I am being harassed for being Muslim?\"\n",
    "docs = combined_retriever.get_relevant_documents(test_query)\n",
    "print(\"Documents Retrieved:\", docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_hate_type(inquiry, retriever=combined_retriever):\n",
    "    \"\"\"\n",
    "    Detect the hate crime type based on the user's inquiry.\n",
    "    \"\"\"\n",
    "    documents = retriever.get_relevant_documents(inquiry)\n",
    "    if documents:\n",
    "        # Extract the hate crime type from the metadata of the first document\n",
    "        source_file = documents[0].metadata.get('source', '')\n",
    "        if source_file:\n",
    "            hate_type = HATE_CRIMES_TYPE.get(source_file.split('/')[-1], \"Unknown Hate Crime\")\n",
    "            return hate_type\n",
    "    return \"No relevant information found.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response_from_retrieval_chain(query, retriever=combined_retriever):\n",
    "    \"\"\"\n",
    "    Retrieve documents based on the query and extract the relevant information.\n",
    "    \"\"\"\n",
    "    documents = retriever.get_relevant_documents(query)\n",
    "    \n",
    "    if documents:\n",
    "        # Print the content of the first document for debugging\n",
    "        print(\"First Document Content:\", documents[0].page_content)\n",
    "        return documents[0].page_content\n",
    "    \n",
    "    return \"No relevant information found.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected Hate Type: anti-religious hate crime\n",
      "First Document Content: Hate\n",
      "Crime\n",
      "Definition\n",
      "●\n",
      "A\n",
      "hate\n",
      "crime\n",
      "(also\n",
      "known\n",
      "as\n",
      "a\n",
      "bias\n",
      "crime)\n",
      "is\n",
      "a\n",
      "crime\n",
      "where\n",
      "a\n",
      "perpetrator\n",
      "targets\n",
      "a\n",
      "victim\n",
      "due\n",
      "to\n",
      "their\n",
      "physical\n",
      "appearance\n",
      "or\n",
      "perceived\n",
      "membership\n",
      "in\n",
      "a\n",
      "specific\n",
      "social\n",
      "group.\n",
      "Such\n",
      "groups\n",
      "may\n",
      "include\n",
      "race,\n",
      "ethnicity ,\n",
      "disability ,\n",
      "language,\n",
      "nationality ,\n",
      "political\n",
      "views,\n",
      "age,\n",
      "religion,\n",
      "sex,\n",
      "gender\n",
      "identity ,\n",
      "or\n",
      "sexual\n",
      "orientation.\n",
      "Non-criminal\n",
      "actions\n",
      "motivated\n",
      "by\n",
      "these\n",
      "biases\n",
      "are\n",
      "often\n",
      "termed\n",
      "“bias\n",
      "incidents.”\n",
      "•\n",
      "Examples\n",
      "of\n",
      "hate\n",
      "crimes\n",
      "include:\n",
      "•\n",
      "Physical\n",
      "assault,\n",
      "homicide,\n",
      "damage\n",
      "to\n",
      "property\n",
      "•\n",
      "Bullying,\n",
      "harassment,\n",
      "verbal\n",
      "abuse,\n",
      "offensive\n",
      "graffiti,\n",
      "or\n",
      "hate\n",
      "mail\n",
      "History\n",
      "of\n",
      "Hate\n",
      "Crimes\n",
      "•\n",
      "Term\n",
      "Origin:\n",
      "The\n",
      "term\n",
      "“hate\n",
      "crime”\n",
      "gained\n",
      "common\n",
      "usage\n",
      "in\n",
      "the\n",
      "U.S.\n",
      "during\n",
      "the\n",
      "1980s,\n",
      "although\n",
      "similar\n",
      "crimes\n",
      "have\n",
      "historical\n",
      "roots.\n",
      "•\n",
      "Historical\n",
      "Examples:\n",
      "•\n",
      "Roman\n",
      "persecution\n",
      "of\n",
      "Response: Hate\n",
      "Crime\n",
      "Definition\n",
      "●\n",
      "A\n",
      "hate\n",
      "crime\n",
      "(also\n",
      "known\n",
      "as\n",
      "a\n",
      "bias\n",
      "crime)\n",
      "is\n",
      "a\n",
      "crime\n",
      "where\n",
      "a\n",
      "perpetrator\n",
      "targets\n",
      "a\n",
      "victim\n",
      "due\n",
      "to\n",
      "their\n",
      "physical\n",
      "appearance\n",
      "or\n",
      "perceived\n",
      "membership\n",
      "in\n",
      "a\n",
      "specific\n",
      "social\n",
      "group.\n",
      "Such\n",
      "groups\n",
      "may\n",
      "include\n",
      "race,\n",
      "ethnicity ,\n",
      "disability ,\n",
      "language,\n",
      "nationality ,\n",
      "political\n",
      "views,\n",
      "age,\n",
      "religion,\n",
      "sex,\n",
      "gender\n",
      "identity ,\n",
      "or\n",
      "sexual\n",
      "orientation.\n",
      "Non-criminal\n",
      "actions\n",
      "motivated\n",
      "by\n",
      "these\n",
      "biases\n",
      "are\n",
      "often\n",
      "termed\n",
      "“bias\n",
      "incidents.”\n",
      "•\n",
      "Examples\n",
      "of\n",
      "hate\n",
      "crimes\n",
      "include:\n",
      "•\n",
      "Physical\n",
      "assault,\n",
      "homicide,\n",
      "damage\n",
      "to\n",
      "property\n",
      "•\n",
      "Bullying,\n",
      "harassment,\n",
      "verbal\n",
      "abuse,\n",
      "offensive\n",
      "graffiti,\n",
      "or\n",
      "hate\n",
      "mail\n",
      "History\n",
      "of\n",
      "Hate\n",
      "Crimes\n",
      "•\n",
      "Term\n",
      "Origin:\n",
      "The\n",
      "term\n",
      "“hate\n",
      "crime”\n",
      "gained\n",
      "common\n",
      "usage\n",
      "in\n",
      "the\n",
      "U.S.\n",
      "during\n",
      "the\n",
      "1980s,\n",
      "although\n",
      "similar\n",
      "crimes\n",
      "have\n",
      "historical\n",
      "roots.\n",
      "•\n",
      "Historical\n",
      "Examples:\n",
      "•\n",
      "Roman\n",
      "persecution\n",
      "of\n"
     ]
    }
   ],
   "source": [
    "# Detect the hate crime type based on the inquiry\n",
    "hate_type = detect_hate_type(\"i have being harassed for being muslim\")\n",
    "print(\"Detected Hate Type:\", hate_type)\n",
    "\n",
    "# Generate a dynamic query based on the detected hate crime type\n",
    "query = generate_dynamic_query(hate_type = False, relevant_laws=True)\n",
    "\n",
    "# Retrieve a response using the retrieval chain\n",
    "response = get_response_from_retrieval_chain(query)\n",
    "print(\"Response:\", response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
